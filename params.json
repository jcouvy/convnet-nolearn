{
  "name": "Experimenting convolutional networks with nolearn",
  "tagline": "><>)))]°>  ><>)))]°>  ><>)))]°>  ><>)))]°>  ><>)))]°>  ><>)))]°>  ><>)))]°>  ><>)))]°>  ><>)))]°>  ><>)))]°>  ><>)))]°>  ><>)))]°>  ",
  "body": "### Who am I ?\r\nI am a french undergraduate student in CS at the University of Bordeaux trying to learn more about _machine learning_,  _security_ and _virtual reality_. This blog aims to help beginners like me, eager to take their first steps in machine learning. I am by no mean an expert of the field (I recommend you to peak at the urls given throughout the tutorial) nor is English my first language so please consider my work with a that in mind.\r\n\r\n## Table of Contents\r\n====================\r\n  + [Prerequisites](#prerequisites)\r\n  + [Introduction](#introduction)\r\n  + [Let's make a first model](#let's-make-a-first-model)\r\n  + [Loading a data-set](#loading-a-data-set)\r\n  + [Choosing a learning method](#choosing-a-learning-method)\r\n  + [Building a proper architecture](#building-a-proper-architecture)\r\n  + [Fine tuning parameters](#how-to-tune-the-number-of-kernels-(filters)-?)\r\n  + [Dealing with overfitting](#the-overfitting-problem)\r\n\r\n## Introduction\r\n___\r\n\r\n\r\n\r\n## Prerequisites\r\n___\r\nIf you want to work on your own you will need to prepare your machine learning toolbox:\r\n+ [Python](http://www.python.org/) 2 >=2.6 or [Python](http://www.python.org/) 3 >=3.3 (we are using Python2.7)\r\n+ Set up a [virtualenv](https://virtualenv.pypa.io/en/stable/) (optional but recommended to keep things stable as nolearn is young and frequently updated)\r\n+ The [nolearn framework](https://github.com/dnouri/nolearn)\r\n+ A text editor of your choice: [GNU Emacs](https://www.gnu.org/software/emacs/) for example (I don't want to start a war here (◕‿◕✿))\r\n+ Access to a GPU with [CUDA](https://developer.nvidia.com/cuda-zone) (you can try simple nets with your CPU only)\r\n\r\n## Let's make a first model\r\n___\r\nWe will start to fiddle with the different layers available. This is where `nolearn` really shines as it allows a clear and easy way to implement your net. First we need to import a few modules:\r\n```python\r\nimport lasagne\r\nfrom lasagne import layers #this allows us to use each pre-defined layer.\r\nfrom nolearn.lasagne import NeuralNet #used to implement your net in a very simple fashion.\r\n```\r\nWe need to initialize our network just like a variable, let's name it `net0`. The initialization is divided in two steps:\r\n- Describe the network architecture (i.e: layer composition)\r\n- Initialize each layer's parameters\r\n\r\n```python\r\nnet0 = NeuralNet(\r\n    layers = [('layer1_name', layers.InsertLayerType),\r\n              ('layer2_name', layers.InsertLayerType),\r\n              (...)],\r\n    layer1_param1 = ..., layer1_param2 = ...,\r\n    layer2_param1 = ..., layer2_param2 = ...,\r\n)\r\n```\r\n**Bear in mind that you need to use the pre-defined parameters name or an error will occur**\r\n\r\nYou are probably not yet familiar with each different layers, no worries we are going to cover that right now. Every single available layer is already implemented in Lasagne and that's good news. Despite being young its documentation is rich and the community is helpful, the following link will get you to the [Lasagne official documentation](https://lasagne.readthedocs.io/en/latest/modules/layers.html) where each layer is described.\r\n\r\nNow that we have the doc opened we can start playing with `net0` :\r\n```python\r\n#from lasagne.updates import sgd\r\n\r\nnet0 = NeuralNet(\r\n    layers = [('input', layers.InputLayer),\r\n              ('conv1', layers.Conv2DLayer),\r\n              ('conv2', layers.Conv2DLayer),\r\n              ('output', layers.DenseLayer)\r\n    ],\r\n    input_shape = (None, 1, 28, 28), \r\n    \r\n    conv1_num_filters =  8,  conv1_filter_size = (3, 3),\r\n    conv2_num_filters =  16, conv2_filter_size = (2, 2),\r\n    \r\n    output_num_units = 10, output_nonlinearity = lasagne.nonlinearities.softmax,\r\n\r\n    #update = sgd,\r\n    #update_learning_rate = 0.01,\r\n    \r\n    max_epochs = 20,\r\n    verbose = 1,\r\n)\r\n```\r\nSo what do we have here...\r\n- `input_shape` describes the data processed by the network. Later on we will use a handwritten digit database named MNIST (you can find more about it [here](http://yann.lecun.com/exdb/mnist/)). Each digit is a 28x28 1-dimensionnal image (grayscale so only 1 color channel).  \r\nNB: the first parameter indicates the size of the batch, `None` means it is not fixed at compile time, thus `nolearn` will figure the value on its own.\r\n- `conv_num_filters` is the amount of filters (or kernels) you will use and `conv_filter_size` specifies their size.\r\n- `output_num_units` means that you sub-sample your data down to 10 images.\r\n- `output_nonlinearity` is the activation function used, here it's the maximum (most commonly used for classification problems).\r\n\r\nPicking the proper sizes seems a little mystical but we will get to that. A nice visualization of the filtering process can be found in a JavaScript implementation [here](http://cs.stanford.edu/people/karpathy/convnetjs/demo/mnist.html) (credits to @Karpathy).\r\n\r\nNow that we have a functional implementation we have to train it !\r\n\r\n## Loading a data-set\r\n___\r\nWe are going to use the set provided in the [Kaggle MNIST competition](https://www.kaggle.com/c/digit-recognizer).\r\n```python\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\n# The competition datafiles are in the directory ../input\r\n# Read training and test data files\r\ntrain = pd.read_csv(\"input/train.csv\")\r\ntest  = pd.read_csv(\"input/test.csv\")\r\n\r\ntrain_images = train.iloc[:,1:].values\r\ntrain_labels = train[[0]].values.ravel()\r\n```\r\nOnce the data-set is loaded we have to add a few lines to start the training: `trainX` is the data used to learn and `trainY` the expected result. This method is called « supervised learning ».\r\n\r\n```python\r\nnet0 = NeuralNet(\r\n    #...\r\n)\r\n# Reshape and normalize training data\r\ntrainX = train_images.reshape(train.shape[0], 1, 28, 28).astype(np.float32)\r\ntrainX /= 255.0\r\n\r\n# Reshape and normalize test data\r\ntestX = test.values.reshape(test.shape[0], 1, 28, 28).astype(np.float32)\r\ntestX /= 255.0\r\n\r\nnet0.fit(trainX, trainY)\r\n```\r\n**Uncomment the lines in** `net0` **if you want to test it yourself**\r\n\r\nThis is the results after 20 epochs (the input display origins from `verbose=1`):\r\n```bash\r\n# Neural Network with 100618 learnable parameters\r\n\r\n## Layer information\r\n\r\n  #  name    size\r\n---  ------  --------\r\n  0  input   1x28x28\r\n  1  conv1   8x26x26\r\n  2  conv2   16x25x25\r\n  3  output  10\r\n\r\n  epoch    train loss    valid loss    train/val    valid acc  dur\r\n-------  ------------  ------------  -----------  -----------  ------\r\n      1       5.16510       0.42123     12.26191      0.86043  10.53s\r\n      2       0.35298       0.30983      1.13928      0.89896  10.58s\r\n      3       0.27154       0.27564      0.98513      0.91174  10.55s\r\n      4       0.23111       0.26905      0.85899      0.91618  10.59s\r\n      5       0.20591       0.26782      0.76883      0.91595  10.71s\r\n      6       0.18814       0.27432      0.68583      0.91678  10.70s\r\n      7       0.17368       0.27859      0.62342      0.91891  10.56s\r\n      8       0.16238       0.28430      0.57115      0.91926  10.69s\r\n      9       0.15185       0.30812      0.49283      0.91541  10.67s\r\n     10       0.14281       0.32322      0.44183      0.91465  10.61s\r\n     11       0.13528       0.33334      0.40583      0.91328  10.59s\r\n     12       0.12717       0.33398      0.38077      0.91358  10.66s\r\n     13       0.12007       0.33142      0.36229      0.91678  10.63s\r\n     14       0.11403       0.33387      0.34153      0.91666  10.61s\r\n     15       0.10853       0.34899      0.31097      0.91571  10.56s\r\n     16       0.10315       0.36111      0.28566      0.91334  10.58s\r\n     17       0.10049       0.35958      0.27947      0.91494  10.56s\r\n     18       0.09618       0.37745      0.25481      0.91370  10.58s\r\n     19       0.09219       0.38261      0.24093      0.91322  10.63s\r\n     20       0.08899       0.41470      0.21458      0.91062  10.68s\r\n```\r\nHuman performance would be above 98%, besides a network is considered industry-viable if its accuracy is at least 95%. We're not there yet but `net0` is really basic.\r\n\r\n## Choosing a learning method\r\n___\r\nThe following graph is a comparison of the commonly used learning methods:\r\n\r\n![learningmethod](https://cloud.githubusercontent.com/assets/19994887/16196236/91019214-36fd-11e6-9e9b-1113334e7261.png)\r\n\r\nOur network will use `nesterov momentum`, it has good performance and allows us to tweak the `learning rate` and `momentum` as the training occurs (better optimization potential).\r\n\r\n## Building a proper architecture\r\n___\r\nTo obtain better results we're going to need more than convolution layers. Most ConvNets are constituted by a successsion of layers as follows (see [the course CS231n from Stanford University](http://cs231n.github.io/convolutional-networks/#layerpat)):\r\n\r\n`INPUT -> [[CONV -> RELU]*N -> POOL?]*M -> [FC -> RELU]*K -> FC`\r\n\r\n* Input Layer\r\n* Convolution Layer + ReLu\r\n* Pooling Layer\r\n* (...)Repeat\r\n* Fully Connected Layer (aka Hidden Layers)\r\n* Output Layer\r\n\r\nConsidering all this we will add a few layers to `net0`:\r\n\r\n```python\r\nnet1 = NeuralNet(\r\n    layers = [('input', layers.InputLayer),\r\n              ('conv1', layers.Conv2DLayer),\r\n              ('pool1', layers.MaxPool2DLayer),\r\n              ('conv2', layers.Conv2DLayer),\r\n              ('pool2', layers.MaxPool2DLayer),\r\n              ('hidden', layers.DenseLayer),\r\n              ('output', layers.DenseLayer)\r\n              ],\r\n              # (...)\r\n)\r\n```\r\n```bash\r\n# Neural Network with 38186 learnable parameters\r\n\r\n  epoch    train loss    valid loss    train/val    valid acc  dur\r\n-------  ------------  ------------  -----------  -----------  -----\r\n      1       1.02026       0.25914      3.93707      0.91891  7.89s\r\n     ..       .......       .......      .......      .......  .....\r\n     10       0.05761       0.08531      0.67536      0.97561  7.88s\r\n     ..       .......       .......      .......      .......  .....\r\n     20       0.02686       0.10420      0.25778      0.97182  7.91s\r\n     ..       .......       .......      .......      .......  .....\r\n     30       0.01065       0.11439      0.09308      0.97691  8.01s\r\n     ..       .......       .......      .......      .......  .....\r\n     40       0.00297       0.14241      0.02082      0.97573  8.04s\r\n     ..       .......       .......      .......      .......  .....\r\n     50       0.00100       0.16171      0.00615      0.97615  7.99s\r\n```\r\nWe notice a few things:\r\n* Lowered amount of learnable parameters (due to the pooling layers).\r\n* The network is a lot faster (consequence of the above). The 2 seconds difference might not feel important to you but a deeper network can be trained for over 3000 epochs. \r\n* Much better accuracy >97%.\r\n\r\nLet's trace a graph using `pyplot` to compare our results:\r\n\r\n![Net0 vs Net1](https://cloud.githubusercontent.com/assets/19994887/16229020/c9d4c666-37ba-11e6-8498-f8c7176c1dec.png)\r\n\r\nBoth `net1` curves drop significantly lower, its a sign we're improving !\r\n\r\n## How to tune the number of kernels (filters) ?\r\n___\r\nNow this is a tricky part... From what I have read and learned it is mostly done empirically. One could say it is \"half intuition, half black magic\". A team of Google researchers tried to explain the importance of proper initialization and gave some guidelines, see [Rethinking the Inception Architecture for Computer Vision](http://arxiv.org/abs/1512.00567).\r\n\r\n For the moment a simple way of proceeding is, firstly, to enable `verbose=2` (it will give us more information about our network's learning capacity of the coverage of its data) then fix a small amount of iteration `max_epochs=10` and test the best combination of kernel sizes (best ratio accuracy/duration for example). We will try to experiment a better way of finding optimal values later on (see part 2).\r\n\r\nLets take a look at the input of `verbose=2` :\r\n```bash\r\n# Neural Network with 38186 learnable parameters\r\n\r\n## Layer information\r\n\r\nname    size        total    cap.Y    cap.X    cov.Y    cov.X\r\n------  --------  -------  -------  -------  -------  -------\r\ninput   1x28x28       784   100.00   100.00   100.00   100.00\r\nconv1   8x26x26      5408   100.00   100.00    10.71    10.71\r\npool1   8x13x13      1352   100.00   100.00    10.71    10.71\r\nconv2   16x12x12     2304    80.00    80.00    17.86    17.86\r\npool2   16x6x6        576    80.00    80.00    17.86    17.86\r\nhidden  64             64   100.00   100.00   100.00   100.00\r\noutput  10             10   100.00   100.00   100.00   100.00\r\n\r\nExplanation\r\n    X, Y:    image dimensions\r\n    cap.:    learning capacity\r\n    cov.:    coverage of image\r\n    magenta: capacity too low (<1/6)\r\n    cyan:    image coverage too high (>100%)\r\n    red:     capacity too low and coverage too high\r\n\r\n```\r\nSadly we cannot see the color scheme here, there is no problem on a terminal though. The output will guide you through a simple optimization of your values. Imagine a network composed of multiple pooling layers, the output would be as follows:\r\n```bash\r\nname    size       total    cap.Y    cap.X    cov.Y    cov.X\r\n------  -------  -------  -------  -------  -------  -------\r\ninput   1x28x28      784   100.00   100.00   100.00   100.00\r\nconv1   8x28x28     6272   100.00   100.00    10.71    10.71\r\npool1   8x14x14     1568   100.00   100.00    10.71    10.71\r\nconv2   8x14x14     1568    85.71    85.71    25.00    25.00\r\npool2   8x7x7        392    85.71    85.71    25.00    25.00\r\nconv3   16x7x7       784    80.00    80.00    53.57    53.57\r\npool3   16x3x3       144    80.00    80.00    53.57    53.57\r\nconv4   16x3x3       144    77.42    77.42   110.71   110.71\r\npool4   16x1x1        16    77.42    77.42   110.71   110.71\r\noutput  10            10   100.00   100.00   100.00   100.00\r\n```\r\nEach pooling layer is sub-sampling the input, the resulting image is really small. On the 4th convolution the network would cover more than 100% of the image surface (should appear in cyan), this is a pretty bad optimization.\r\n\r\n## The overfitting problem\r\n___\r\nTo understand the issue we need to scroll back to the `net1` graph. Even though the results are better we can clearly see the `train/loss` value (depicted in red) increase while the `valid/loss` steadily decreases. This is often a situation where overfitting have occured. But what is « overfitting » ?\r\n\r\n> In statistics and machine learning, one of the most common tasks is to fit a \"model\" to a set of training data, so as to be able to make reliable predictions on general untrained data. In overfitting, a statistical model describes **random error** or **noise** instead of the underlying relationship. Overfitting occurs when a model is excessively complex, such as having too many parameters relative to the number of observations. A model that has been overfit has **poor predictive performance**, as it overreacts to minor fluctuations in the training data.  \r\n_(source: https://en.wikipedia.org/wiki/Overfitting)_\r\n\r\nThe definition might not be clear to everyone, focus on the highlighted parts. We can easily assume two things: \r\n+ Overfitting is a common issue in ML.\r\n+ We want to get rid of it as best as we can.\r\n\r\nThere are different ways to deal with overfitting, in `net2` we will try to use the `BatchIterator` provided by `nolearn` to simulate a larger amount of data. This technique is called **Data augmentation**.\r\n\r\n```python\r\nfrom nolearn.lasagne import BatchIterator, #...\r\n\r\n# Custom Batch Iterator called by NeuralNet to provided augmented\r\n# data in order to reduce overfitting.\r\n# Randomly crops by 2 pixels the inputed image.\r\n# Returns the new tensor Xb (trainX) and the labels.\r\nclass CropBatchIterator(BatchIterator):\r\n    cropX, cropY = 2, 2\r\n    def transform(self, Xb, yb):\r\n        Xb, yb = super(CropBatchIterator, self).transform(Xb, yb)\r\n        shape = Xb.shape[0]\r\n        width = 28 - self.cropX\r\n        height = 28 - self.cropY\r\n        new_Xb = np.zeros([shape, 1, width, height], dtype=np.float32)\r\n        for i in range (shape):\r\n            dx = np.random.randint(self.cropX+1)\r\n            dy = np.random.randint(self.cropY+1)\r\n            new_Xb[i] = Xb[i, :, dy:dy+width, dx:dx+height]\r\n        return new_Xb, yb\r\n\r\n```\r\n\r\nWe need to add a few lines to our network to make it work properly. You might notice the architecture changed a little, this is what I found to be a decent set of parameters (see [Fine tuning parameters](#how-to-tune-the-number-of-kernels-(filters)-?))\r\n\r\n```python\r\nnet2 = NeuralNet(\r\n    layers = [('input', layers.InputLayer),\r\n              ('conv1', layers.Conv2DLayer),\r\n              ('pool1', layers.MaxPool2DLayer),\r\n              ('conv2', layers.Conv2DLayer),\r\n              ('pool2', layers.MaxPool2DLayer),\r\n              ('hidden1', layers.DenseLayer),\r\n              ('hidden2', layers.DenseLayer),\r\n              ('output', layers.DenseLayer)\r\n              ],\r\n    # Each digit is a 28x28 1-Dimensionnal image,\r\n    # We crop each image by 2 pixels in width and height.\r\n    input_shape = (None, 1, 26, 26),\r\n\r\n    conv1_num_filters =  13, conv1_filter_size = (3, 3),\r\n    conv1_nonlinearity = lasagne.nonlinearities.rectify, #ReLu rectifier (default value)\r\n    pool1_pool_size = (2, 2),\r\n    \r\n    conv2_num_filters = 26, conv2_filter_size = (2, 2),\r\n    conv2_nonlinearity = lasagne.nonlinearities.rectify,\r\n    pool2_pool_size = (2, 2),\r\n\r\n    hidden1_num_units = 128, hidden2_num_units = 128,\r\n    output_num_units = 10, \r\n    output_nonlinearity = lasagne.nonlinearities.softmax, #Softmax classifier (default value)\r\n\r\n    # Learning method.\r\n    update = nesterov_momentum,\r\n    update_learning_rate = 0.01,\r\n    update_momentum = 0.9,    \r\n\r\n    # Calls the class CropBatchIterator while training occurs\r\n    # Doesn't affect GPU performance as the CPU deals with the\r\n    # cropping operation.\r\n    batch_iterator_train = CropBatchIterator(batch_size=200),\r\n    batch_iterator_test = CropBatchIterator(batch_size=200),\r\n\r\n    regression = False,\r\n    max_epochs = 500,\r\n\r\n    # Deeper layer information (learning capacity, coverage...)\r\n    verbose = 2, \r\n)\r\n```\r\n![net1net2](https://cloud.githubusercontent.com/assets/19994887/16303398/bb9328a8-3950-11e6-8185-547eb1e7cd0c.png)\r\n\r\nWe also manage to obtain better results with nearly 99% on average, however the network still tends to be overfitting a little (the reason is probably that MNIST is too simple).\r\n\r\n```bash\r\n epoch    train loss    valid loss    train/val    valid acc  dur\r\n-------  ------------  ------------  -----------  -----------  -----\r\n      1       1.18662       0.40577      2.92434      0.87733  8.72s\r\n     ..       .......       .......      .......      .......  .....\r\n     50       0.01686       0.04535      0.37183      0.98744  8.79s\r\n     ..       .......       .......      .......      .......  .....\r\n    100       0.00561       0.05057      0.11096      0.98733  8.82s\r\n     ..       .......       .......      .......      .......  .....\r\n    200       0.00095       0.06931      0.01376      0.98721  8.81s\r\n     ..       .......       .......      .......      .......  .....\r\n    300       0.00007       0.06970      0.00101      0.98930  8.76s\r\n     ..       .......       .......      .......      .......  .....\r\n    400       0.00004       0.07738      0.00045      0.99000  8.70s\r\n     ..       .......       .......      .......      .......  .....\r\n    450       0.00003       0.06610      0.00039      0.99000  8.83s\r\n     ..       .......       .......      .......      .......  .....\r\n    500       0.00002       0.07326      0.00030      0.98884  8.71s\r\n\r\n```\r\n### Credits\r\nDaniel Nouri (@dnouri) author of nolearn and Andrej Karpathy (@karpathy) for his ML courses.",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}