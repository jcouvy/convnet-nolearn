<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Experimenting convolutional networks with nolearn by jcouvy</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Experimenting convolutional networks with nolearn</h1>
      <h2 class="project-tagline">&gt;&lt;&gt;)))]°&gt;  &gt;&lt;&gt;)))]°&gt;  &gt;&lt;&gt;)))]°&gt;  &gt;&lt;&gt;)))]°&gt;  &gt;&lt;&gt;)))]°&gt;  &gt;&lt;&gt;)))]°&gt;  &gt;&lt;&gt;)))]°&gt;  &gt;&lt;&gt;)))]°&gt;  &gt;&lt;&gt;)))]°&gt;  &gt;&lt;&gt;)))]°&gt;  &gt;&lt;&gt;)))]°&gt;  &gt;&lt;&gt;)))]°&gt;  </h2>
      <a href="https://github.com/jcouvy/convnet-nolearn" class="btn">View on GitHub</a>
      <a href="https://github.com/jcouvy/convnet-nolearn/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/jcouvy/convnet-nolearn/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h3>
<a id="who-am-i-" class="anchor" href="#who-am-i-" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Who am I ?</h3>

<p>I am a french undergraduate student in CS at the University of Bordeaux trying to learn more about <em>machine learning</em>,  <em>security</em>. This blog aims to help beginners like me, eager to take their first steps in machine learning. I am by no mean an expert of the field (I recommend you to peak at the urls given throughout the tutorial) nor is English my first language so please consider my work with a that in mind.</p>

<h2>
<a id="table-of-contents" class="anchor" href="#table-of-contents" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Table of Contents</h2>

<h1></h1>

<ul>
<li><a href="#prerequisites">Prerequisites</a></li>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#let's-make-a-first-model">Let's make a first model</a></li>
<li><a href="#loading-a-data-set">Loading a data-set</a></li>
<li><a href="#choosing-a-learning-method">Choosing a learning method</a></li>
<li><a href="#building-a-proper-architecture">Building a proper architecture</a></li>
<li><a href="#how-to-tune-the-number-of-kernels-(filters)-?">Fine tuning parameters</a></li>
<li><a href="#the-overfitting-problem">Dealing with overfitting</a></li>
<li><a href="#further-improvements">Further improvements</a></li>
</ul>

<h2>
<a id="introduction" class="anchor" href="#introduction" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Introduction</h2>

<hr>

<h2>
<a id="prerequisites" class="anchor" href="#prerequisites" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Prerequisites</h2>

<hr>

<p>If you want to work on your own you will need to prepare your machine learning toolbox:</p>

<ul>
<li>
<a href="http://www.python.org/">Python</a> 2 &gt;=2.6 or <a href="http://www.python.org/">Python</a> 3 &gt;=3.3 (we are using Python2.7)</li>
<li>Set up a <a href="https://virtualenv.pypa.io/en/stable/">virtualenv</a> (optional but recommended to keep things stable as nolearn is young and frequently updated)</li>
<li>The <a href="https://github.com/dnouri/nolearn">nolearn framework</a>
</li>
<li>A text editor of your choice: <a href="https://www.gnu.org/software/emacs/">GNU Emacs</a> for example (I don't want to start a war here (◕‿◕✿))</li>
<li>Access to a GPU with <a href="https://developer.nvidia.com/cuda-zone">CUDA</a> (you can try simple nets with your CPU only)</li>
</ul>

<h2>
<a id="lets-make-a-first-model" class="anchor" href="#lets-make-a-first-model" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Let's make a first model</h2>

<hr>

<p>We will start to fiddle with the different layers available. This is where <code>nolearn</code> really shines as it allows a clear and easy way to implement your net. First we need to import a few modules:</p>

<div class="highlight highlight-source-python"><pre><span class="pl-k">import</span> lasagne
<span class="pl-k">from</span> lasagne <span class="pl-k">import</span> layers <span class="pl-c">#this allows us to use each pre-defined layer.</span>
<span class="pl-k">from</span> nolearn.lasagne <span class="pl-k">import</span> NeuralNet <span class="pl-c">#used to implement your net in a very simple fashion.</span></pre></div>

<p>We need to initialize our network just like a variable, let's name it <code>net0</code>. The initialization is divided in two steps:</p>

<ul>
<li>Describe the network architecture (i.e: layer composition)</li>
<li>Initialize each layer's parameters</li>
</ul>

<div class="highlight highlight-source-python"><pre>net0 <span class="pl-k">=</span> NeuralNet(
    <span class="pl-v">layers</span> <span class="pl-k">=</span> [(<span class="pl-s"><span class="pl-pds">'</span>layer1_name<span class="pl-pds">'</span></span>, layers.InsertLayerType),
              (<span class="pl-s"><span class="pl-pds">'</span>layer2_name<span class="pl-pds">'</span></span>, layers.InsertLayerType),
              (<span class="pl-c1">...</span>)],
    <span class="pl-v">layer1_param1</span> <span class="pl-k">=</span> <span class="pl-c1">...</span>, <span class="pl-v">layer1_param2</span> <span class="pl-k">=</span> <span class="pl-c1">...</span>,
    <span class="pl-v">layer2_param1</span> <span class="pl-k">=</span> <span class="pl-c1">...</span>, <span class="pl-v">layer2_param2</span> <span class="pl-k">=</span> <span class="pl-c1">...</span>,
)</pre></div>

<p><strong>Bear in mind that you need to use the pre-defined parameters names or an error will occur</strong></p>

<p>You are probably not yet familiar with each different layers, no worries we are going to cover that right now. Every single available layer is already implemented in Lasagne and that's good news. Despite being young its documentation is rich and the community is helpful, the following link will get you to the <a href="https://lasagne.readthedocs.io/en/latest/modules/layers.html">Lasagne official documentation</a> where each layer is described.</p>

<p>Now that we have the doc opened we can start playing with <code>net0</code> :</p>

<div class="highlight highlight-source-python"><pre><span class="pl-c">#from lasagne.updates import sgd</span>

net0 <span class="pl-k">=</span> NeuralNet(
    <span class="pl-v">layers</span> <span class="pl-k">=</span> [(<span class="pl-s"><span class="pl-pds">'</span>input<span class="pl-pds">'</span></span>, layers.InputLayer),
              (<span class="pl-s"><span class="pl-pds">'</span>conv1<span class="pl-pds">'</span></span>, layers.Conv2DLayer),
              (<span class="pl-s"><span class="pl-pds">'</span>conv2<span class="pl-pds">'</span></span>, layers.Conv2DLayer),
              (<span class="pl-s"><span class="pl-pds">'</span>output<span class="pl-pds">'</span></span>, layers.DenseLayer)
    ],
    <span class="pl-v">input_shape</span> <span class="pl-k">=</span> (<span class="pl-c1">None</span>, <span class="pl-c1">1</span>, <span class="pl-c1">28</span>, <span class="pl-c1">28</span>), 

    <span class="pl-v">conv1_num_filters</span> <span class="pl-k">=</span>  <span class="pl-c1">8</span>,  <span class="pl-v">conv1_filter_size</span> <span class="pl-k">=</span> (<span class="pl-c1">3</span>, <span class="pl-c1">3</span>),
    <span class="pl-v">conv2_num_filters</span> <span class="pl-k">=</span>  <span class="pl-c1">16</span>, <span class="pl-v">conv2_filter_size</span> <span class="pl-k">=</span> (<span class="pl-c1">2</span>, <span class="pl-c1">2</span>),

    <span class="pl-v">output_num_units</span> <span class="pl-k">=</span> <span class="pl-c1">10</span>, <span class="pl-v">output_nonlinearity</span> <span class="pl-k">=</span> lasagne.nonlinearities.softmax,

    <span class="pl-c">#update = sgd,</span>
    <span class="pl-c">#update_learning_rate = 0.01,</span>

    <span class="pl-v">max_epochs</span> <span class="pl-k">=</span> <span class="pl-c1">20</span>,
    <span class="pl-v">verbose</span> <span class="pl-k">=</span> <span class="pl-c1">1</span>,
)</pre></div>

<p>So what do we have here...</p>

<ul>
<li>
<code>input_shape</code> describes the data processed by the network. Later on we will use a handwritten digit database named MNIST (you can find more about it <a href="http://yann.lecun.com/exdb/mnist/">here</a>). Each digit is a 28x28 1-dimensionnal image (grayscale so only 1 color channel).<br>
NB: the first parameter indicates the size of the batch, <code>None</code> means it is not fixed at compile time, thus <code>nolearn</code> will figure the value on its own.</li>
<li>
<code>conv_num_filters</code> is the amount of filters (or kernels) you will use and <code>conv_filter_size</code> specifies their size.</li>
<li>
<code>output_num_units</code> means that you sub-sample your data down to 10 images.</li>
<li>
<code>output_nonlinearity</code> is the activation function used, here it's the maximum (most commonly used for classification problems).</li>
</ul>

<p>Picking the proper sizes seems a little mystical but we will get to that. A nice visualization of the filtering process can be found in a JavaScript implementation <a href="http://cs.stanford.edu/people/karpathy/convnetjs/demo/mnist.html">here</a> (credits to <a href="https://github.com/Karpathy" class="user-mention">@Karpathy</a>).</p>

<p>Now that we have a functional implementation we have to train it !</p>

<h2>
<a id="loading-a-data-set" class="anchor" href="#loading-a-data-set" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Loading a data-set</h2>

<hr>

<p>We are going to use the set provided in the <a href="https://www.kaggle.com/c/digit-recognizer">Kaggle MNIST competition</a>.</p>

<div class="highlight highlight-source-python"><pre><span class="pl-k">import</span> pandas <span class="pl-k">as</span> pd
<span class="pl-k">import</span> numpy <span class="pl-k">as</span> np

<span class="pl-c"># The competition datafiles are in the directory ../input</span>
<span class="pl-c"># Read training and test data files</span>
train <span class="pl-k">=</span> pd.read_csv(<span class="pl-s"><span class="pl-pds">"</span>input/train.csv<span class="pl-pds">"</span></span>)
test  <span class="pl-k">=</span> pd.read_csv(<span class="pl-s"><span class="pl-pds">"</span>input/test.csv<span class="pl-pds">"</span></span>)

train_images <span class="pl-k">=</span> train.iloc[:,<span class="pl-c1">1</span>:].values
train_labels <span class="pl-k">=</span> train[[<span class="pl-c1">0</span>]].values.ravel()</pre></div>

<p>Once the data-set is loaded we have to add a few lines to start the training: <code>trainX</code> is the data used to learn and <code>trainY</code> the expected result. This method is called « supervised learning ».</p>

<div class="highlight highlight-source-python"><pre>net0 <span class="pl-k">=</span> NeuralNet(
    <span class="pl-c">#...</span>
)
<span class="pl-c"># Reshape and normalize training data</span>
trainX <span class="pl-k">=</span> train_images.reshape(train.shape[<span class="pl-c1">0</span>], <span class="pl-c1">1</span>, <span class="pl-c1">28</span>, <span class="pl-c1">28</span>).astype(np.float32)
trainX <span class="pl-k">/=</span> <span class="pl-c1">255.0</span>

<span class="pl-c"># Reshape and normalize test data</span>
testX <span class="pl-k">=</span> test.values.reshape(test.shape[<span class="pl-c1">0</span>], <span class="pl-c1">1</span>, <span class="pl-c1">28</span>, <span class="pl-c1">28</span>).astype(np.float32)
testX <span class="pl-k">/=</span> <span class="pl-c1">255.0</span>

net0.fit(trainX, trainY)</pre></div>

<p><strong>Uncomment the lines in</strong> <code>net0</code> <strong>if you want to test it yourself</strong></p>

<p>This is the results after 20 epochs (the input display origins from <code>verbose=1</code>):</p>

<div class="highlight highlight-source-shell"><pre><span class="pl-c"># Neural Network with 100618 learnable parameters</span>

<span class="pl-c">## Layer information</span>

  <span class="pl-c">#  name    size</span>
---  ------  --------
  0  input   1x28x28
  1  conv1   8x26x26
  2  conv2   16x25x25
  3  output  10

  epoch    train loss    valid loss    train/val    valid acc  dur
-------  ------------  ------------  -----------  -----------  ------
      1       5.16510       0.42123     12.26191      0.86043  10.53s
      2       0.35298       0.30983      1.13928      0.89896  10.58s
      3       0.27154       0.27564      0.98513      0.91174  10.55s
      4       0.23111       0.26905      0.85899      0.91618  10.59s
      5       0.20591       0.26782      0.76883      0.91595  10.71s
      6       0.18814       0.27432      0.68583      0.91678  10.70s
      7       0.17368       0.27859      0.62342      0.91891  10.56s
      8       0.16238       0.28430      0.57115      0.91926  10.69s
      9       0.15185       0.30812      0.49283      0.91541  10.67s
     10       0.14281       0.32322      0.44183      0.91465  10.61s
     11       0.13528       0.33334      0.40583      0.91328  10.59s
     12       0.12717       0.33398      0.38077      0.91358  10.66s
     13       0.12007       0.33142      0.36229      0.91678  10.63s
     14       0.11403       0.33387      0.34153      0.91666  10.61s
     15       0.10853       0.34899      0.31097      0.91571  10.56s
     16       0.10315       0.36111      0.28566      0.91334  10.58s
     17       0.10049       0.35958      0.27947      0.91494  10.56s
     18       0.09618       0.37745      0.25481      0.91370  10.58s
     19       0.09219       0.38261      0.24093      0.91322  10.63s
     20       0.08899       0.41470      0.21458      0.91062  10.68s</pre></div>

<p>Human performance would be above 98%, besides a network is considered industry-viable if its accuracy is at least 95%. We're not there yet but <code>net0</code> is really basic.</p>

<h2>
<a id="choosing-a-learning-method" class="anchor" href="#choosing-a-learning-method" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Choosing a learning method</h2>

<hr>

<p>We just learned that the origins of artificial neural networks are found in biomimetism. Our goal is to build a network able to learn like a brain would do. However not every problem can be practically adapted into code by a programmer, this is where learning algorithms become useful. There are three major learning paradigms :</p>

<ul>
<li>Supervised learning (the one we will focus on)</li>
<li>Unsupervised learning</li>
<li>Reinforcement learning</li>
</ul>

<p>There are plenty of information about these methods elsewhere on the web or in your favorite library so we won't cover them up here. The following graph is a comparison of the commonly used supervised learning methods:</p>

<p><img src="https://cloud.githubusercontent.com/assets/19994887/16196236/91019214-36fd-11e6-9e9b-1113334e7261.png" alt="learningmethod"></p>

<p>Our network will use <code>nesterov momentum</code> for two reasons, firstly it has good performance and secondly it requires to specify both a learning rate and momentum values (this will be helpful later).</p>

<h2>
<a id="building-a-proper-architecture" class="anchor" href="#building-a-proper-architecture" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building a proper architecture</h2>

<hr>

<p>To obtain better results than <code>net0</code> we are going to need more than convolution layers. Most ConvNets are constituted by a succession of different layers following a specific pattern (see <a href="http://cs231n.github.io/convolutional-networks/#layerpat">the course CS231n from Stanford University</a>):</p>

<blockquote>
<p>The most common form of a ConvNet architecture stacks a few CONV-RELU layers, follows them with POOL layers, and repeats this pattern until the image has been merged spatially to a small size. At some point, it is common to transition to fully-connected layers. The last fully-connected layer holds the output, such as the class scores. In other words, the most common ConvNet architecture follows the pattern:  </p>
</blockquote>

<p><code>INPUT -&gt; [[CONV -&gt; RELU]*N -&gt; POOL?]*M -&gt; [FC -&gt; RELU]*K -&gt; FC</code></p>

<blockquote>
<p>Where the <code>*</code> indicates repetition, and the <code>POOL?</code> indicates an optional pooling layer. Moreover, <code>N &gt;= 0</code> (and usually <code>N &lt;= 3</code>), <code>M &gt;= 0</code>, <code>K &gt;= 0</code> (and usually <code>K &lt; 3</code>).</p>
</blockquote>

<p>Considering all this we will add a few layers to <code>net0</code>:</p>

<div class="highlight highlight-source-python"><pre>net1 <span class="pl-k">=</span> NeuralNet(
    <span class="pl-v">layers</span> <span class="pl-k">=</span> [(<span class="pl-s"><span class="pl-pds">'</span>input<span class="pl-pds">'</span></span>, layers.InputLayer),
              (<span class="pl-s"><span class="pl-pds">'</span>conv1<span class="pl-pds">'</span></span>, layers.Conv2DLayer),
              (<span class="pl-s"><span class="pl-pds">'</span>pool1<span class="pl-pds">'</span></span>, layers.MaxPool2DLayer),
              (<span class="pl-s"><span class="pl-pds">'</span>conv2<span class="pl-pds">'</span></span>, layers.Conv2DLayer),
              (<span class="pl-s"><span class="pl-pds">'</span>pool2<span class="pl-pds">'</span></span>, layers.MaxPool2DLayer),
              (<span class="pl-s"><span class="pl-pds">'</span>hidden<span class="pl-pds">'</span></span>, layers.DenseLayer),
              (<span class="pl-s"><span class="pl-pds">'</span>output<span class="pl-pds">'</span></span>, layers.DenseLayer)
              ],
              <span class="pl-c"># (...)</span>
)</pre></div>

<div class="highlight highlight-source-shell"><pre><span class="pl-c"># Neural Network with 38186 learnable parameters</span>

  epoch    train loss    valid loss    train/val    valid acc  dur
-------  ------------  ------------  -----------  -----------  -----
      1       1.02026       0.25914      3.93707      0.91891  7.89s
     ..       .......       .......      .......      .......  .....
     10       0.05761       0.08531      0.67536      0.97561  7.88s
     ..       .......       .......      .......      .......  .....
     20       0.02686       0.10420      0.25778      0.97182  7.91s
     ..       .......       .......      .......      .......  .....
     30       0.01065       0.11439      0.09308      0.97691  8.01s
     ..       .......       .......      .......      .......  .....
     40       0.00297       0.14241      0.02082      0.97573  8.04s
     ..       .......       .......      .......      .......  .....
     50       0.00100       0.16171      0.00615      0.97615  7.99s</pre></div>

<p>We notice a few things:</p>

<ul>
<li>Lowered amount of learnable parameters (due to the pooling layers).</li>
<li>The network is a lot faster (consequence of the above). The 2 seconds difference might not feel important to you but a deeper network can be trained for over 3000 epochs. </li>
<li>Much better accuracy &gt;97%.</li>
</ul>

<p>Let's trace a graph using <code>pyplot</code> to compare our results:</p>

<p><img src="https://cloud.githubusercontent.com/assets/19994887/16229020/c9d4c666-37ba-11e6-8498-f8c7176c1dec.png" alt="Net0 vs Net1"></p>

<p>Both <code>net1</code> curves drop significantly lower, its a sign we're improving !</p>

<h2>
<a id="how-to-tune-the-number-of-kernels-filters-" class="anchor" href="#how-to-tune-the-number-of-kernels-filters-" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>How to tune the number of kernels (filters) ?</h2>

<hr>

<p>Now this is a tricky part... From what I have read and learned it is mostly done empirically. One could say it is "half intuition, half black magic". A team of Google researchers tried to explain the importance of proper initialization and gave some guidelines, see <a href="http://arxiv.org/abs/1512.00567">Rethinking the Inception Architecture for Computer Vision</a>.</p>

<p>For the moment a simple way of proceeding is, firstly, to enable <code>verbose=2</code> (it will give us more information about our network's learning capacity of the coverage of its data) then fix a small amount of iteration <code>max_epochs=10</code> and test the best combination of kernel sizes (best ratio accuracy/duration for example). We will try to experiment a better way of finding optimal values later on (see part 2).</p>

<p>Lets take a look at the input of <code>verbose=2</code> :</p>

<div class="highlight highlight-source-shell"><pre><span class="pl-c"># Neural Network with 38186 learnable parameters</span>

<span class="pl-c">## Layer information</span>

name    size        total    cap.Y    cap.X    cov.Y    cov.X
------  --------  -------  -------  -------  -------  -------
input   1x28x28       784   100.00   100.00   100.00   100.00
conv1   8x26x26      5408   100.00   100.00    10.71    10.71
pool1   8x13x13      1352   100.00   100.00    10.71    10.71
conv2   16x12x12     2304    80.00    80.00    17.86    17.86
pool2   16x6x6        576    80.00    80.00    17.86    17.86
hidden  64             64   100.00   100.00   100.00   100.00
output  10             10   100.00   100.00   100.00   100.00

Explanation
    X, Y:    image dimensions
    cap.:    learning capacity
    cov.:    coverage of image
    magenta: capacity too low (<span class="pl-k">&lt;</span>1/6)
    cyan:    image coverage too high (<span class="pl-k">&gt;</span>100%)
    red:     capacity too low and coverage too high
</pre></div>

<p>Sadly we cannot see the color scheme here, there is no problem on a terminal though. The output will guide you through a simple optimization of your values. Imagine a network composed of multiple pooling layers, the output would be as follows:</p>

<div class="highlight highlight-source-shell"><pre>name    size       total    cap.Y    cap.X    cov.Y    cov.X
------  -------  -------  -------  -------  -------  -------
input   1x28x28      784   100.00   100.00   100.00   100.00
conv1   8x28x28     6272   100.00   100.00    10.71    10.71
pool1   8x14x14     1568   100.00   100.00    10.71    10.71
conv2   8x14x14     1568    85.71    85.71    25.00    25.00
pool2   8x7x7        392    85.71    85.71    25.00    25.00
conv3   16x7x7       784    80.00    80.00    53.57    53.57
pool3   16x3x3       144    80.00    80.00    53.57    53.57
conv4   16x3x3       144    77.42    77.42   110.71   110.71
pool4   16x1x1        16    77.42    77.42   110.71   110.71
output  10            10   100.00   100.00   100.00   100.00</pre></div>

<p>Each pooling layer is sub-sampling the input, the resulting image is really small. On the 4th convolution the network would cover more than 100% of the image surface (should appear in cyan), this is a pretty bad optimization.</p>

<h2>
<a id="the-overfitting-problem" class="anchor" href="#the-overfitting-problem" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>The overfitting problem</h2>

<hr>

<p>To understand the issue we need to scroll back to the <code>net1</code> graph. Even though the results are better we can clearly see the <code>train/loss</code> value (depicted in red) increase while the <code>valid/loss</code> steadily decreases. This is often a situation where overfitting have occured. But what is « overfitting » ?</p>

<blockquote>
<p>In statistics and machine learning, one of the most common tasks is to fit a "model" to a set of training data, so as to be able to make reliable predictions on general untrained data. In overfitting, a statistical model describes <strong>random error</strong> or <strong>noise</strong> instead of the underlying relationship. Overfitting occurs when a model is excessively complex, such as having too many parameters relative to the number of observations. A model that has been overfit has <strong>poor predictive performance</strong>, as it overreacts to minor fluctuations in the training data.<br>
<em>(source: <a href="https://en.wikipedia.org/wiki/Overfitting">https://en.wikipedia.org/wiki/Overfitting</a>)</em></p>
</blockquote>

<p>The definition might not be clear to everyone, focus on the highlighted parts. We can easily assume two things: </p>

<ul>
<li>Overfitting is a common issue in ML.</li>
<li>We want to get rid of it as best as we can.</li>
</ul>

<p>There are different ways to deal with overfitting, in <code>net2</code> we will try to use the <code>BatchIterator</code> provided by <code>nolearn</code> to simulate a larger amount of data. This technique is called <strong>Data augmentation</strong>.</p>

<div class="highlight highlight-source-python"><pre><span class="pl-k">from</span> nolearn.lasagne <span class="pl-k">import</span> BatchIterator, <span class="pl-c">#...</span>

<span class="pl-c"># Custom Batch Iterator called by NeuralNet to provided augmented</span>
<span class="pl-c"># data in order to reduce overfitting.</span>
<span class="pl-c"># Randomly crops by 2 pixels the inputed image.</span>
<span class="pl-c"># Returns the new tensor Xb (trainX) and the labels.</span>
<span class="pl-k">class</span> <span class="pl-en">CropBatchIterator</span>(<span class="pl-e">BatchIterator</span>):
    cropX, cropY <span class="pl-k">=</span> <span class="pl-c1">2</span>, <span class="pl-c1">2</span>
    <span class="pl-k">def</span> <span class="pl-en">transform</span>(<span class="pl-smi"><span class="pl-smi">self</span></span>, <span class="pl-smi">Xb</span>, <span class="pl-smi">yb</span>):
        Xb, yb <span class="pl-k">=</span> <span class="pl-c1">super</span>(CropBatchIterator, <span class="pl-v">self</span>).transform(Xb, yb)
        shape <span class="pl-k">=</span> Xb.shape[<span class="pl-c1">0</span>]
        width <span class="pl-k">=</span> <span class="pl-c1">28</span> <span class="pl-k">-</span> <span class="pl-v">self</span>.cropX
        height <span class="pl-k">=</span> <span class="pl-c1">28</span> <span class="pl-k">-</span> <span class="pl-v">self</span>.cropY
        new_Xb <span class="pl-k">=</span> np.zeros([shape, <span class="pl-c1">1</span>, width, height], <span class="pl-v">dtype</span><span class="pl-k">=</span>np.float32)
        <span class="pl-k">for</span> i <span class="pl-k">in</span> <span class="pl-c1">range</span> (shape):
            dx <span class="pl-k">=</span> np.random.randint(<span class="pl-v">self</span>.cropX<span class="pl-k">+</span><span class="pl-c1">1</span>)
            dy <span class="pl-k">=</span> np.random.randint(<span class="pl-v">self</span>.cropY<span class="pl-k">+</span><span class="pl-c1">1</span>)
            new_Xb[i] <span class="pl-k">=</span> Xb[i, :, dy:dy<span class="pl-k">+</span>width, dx:dx<span class="pl-k">+</span>height]
        <span class="pl-k">return</span> new_Xb, yb
</pre></div>

<p>We need to add a few lines to our network to make it work properly. You might notice the architecture changed a little, this is what I found to be a decent set of parameters (see <a href="#how-to-tune-the-number-of-kernels-(filters)-?">Fine tuning parameters</a>)</p>

<div class="highlight highlight-source-python"><pre>net2 <span class="pl-k">=</span> NeuralNet(
    <span class="pl-v">layers</span> <span class="pl-k">=</span> [(<span class="pl-s"><span class="pl-pds">'</span>input<span class="pl-pds">'</span></span>, layers.InputLayer),
              (<span class="pl-s"><span class="pl-pds">'</span>conv1<span class="pl-pds">'</span></span>, layers.Conv2DLayer),
              (<span class="pl-s"><span class="pl-pds">'</span>pool1<span class="pl-pds">'</span></span>, layers.MaxPool2DLayer),
              (<span class="pl-s"><span class="pl-pds">'</span>conv2<span class="pl-pds">'</span></span>, layers.Conv2DLayer),
              (<span class="pl-s"><span class="pl-pds">'</span>pool2<span class="pl-pds">'</span></span>, layers.MaxPool2DLayer),
              (<span class="pl-s"><span class="pl-pds">'</span>hidden1<span class="pl-pds">'</span></span>, layers.DenseLayer),
              (<span class="pl-s"><span class="pl-pds">'</span>hidden2<span class="pl-pds">'</span></span>, layers.DenseLayer),
              (<span class="pl-s"><span class="pl-pds">'</span>output<span class="pl-pds">'</span></span>, layers.DenseLayer)
              ],
    <span class="pl-c"># Each digit is a 28x28 1-Dimensionnal image,</span>
    <span class="pl-c"># We crop each image by 2 pixels in width and height.</span>
    <span class="pl-v">input_shape</span> <span class="pl-k">=</span> (<span class="pl-c1">None</span>, <span class="pl-c1">1</span>, <span class="pl-c1">26</span>, <span class="pl-c1">26</span>),

    <span class="pl-v">conv1_num_filters</span> <span class="pl-k">=</span>  <span class="pl-c1">13</span>, <span class="pl-v">conv1_filter_size</span> <span class="pl-k">=</span> (<span class="pl-c1">3</span>, <span class="pl-c1">3</span>),
    <span class="pl-v">conv1_nonlinearity</span> <span class="pl-k">=</span> lasagne.nonlinearities.rectify, <span class="pl-c">#ReLu rectifier (default value)</span>
    <span class="pl-v">pool1_pool_size</span> <span class="pl-k">=</span> (<span class="pl-c1">2</span>, <span class="pl-c1">2</span>),

    <span class="pl-v">conv2_num_filters</span> <span class="pl-k">=</span> <span class="pl-c1">26</span>, <span class="pl-v">conv2_filter_size</span> <span class="pl-k">=</span> (<span class="pl-c1">2</span>, <span class="pl-c1">2</span>),
    <span class="pl-v">conv2_nonlinearity</span> <span class="pl-k">=</span> lasagne.nonlinearities.rectify,
    <span class="pl-v">pool2_pool_size</span> <span class="pl-k">=</span> (<span class="pl-c1">2</span>, <span class="pl-c1">2</span>),

    <span class="pl-v">hidden1_num_units</span> <span class="pl-k">=</span> <span class="pl-c1">128</span>, <span class="pl-v">hidden2_num_units</span> <span class="pl-k">=</span> <span class="pl-c1">128</span>,
    <span class="pl-v">output_num_units</span> <span class="pl-k">=</span> <span class="pl-c1">10</span>, 
    <span class="pl-v">output_nonlinearity</span> <span class="pl-k">=</span> lasagne.nonlinearities.softmax, <span class="pl-c">#Softmax classifier (default value)</span>

    <span class="pl-c"># Learning method.</span>
    <span class="pl-v">update</span> <span class="pl-k">=</span> nesterov_momentum,
    <span class="pl-v">update_learning_rate</span> <span class="pl-k">=</span> <span class="pl-c1">0.01</span>,
    <span class="pl-v">update_momentum</span> <span class="pl-k">=</span> <span class="pl-c1">0.9</span>,    

    <span class="pl-c"># Calls the class CropBatchIterator while training occurs</span>
    <span class="pl-c"># Doesn't affect GPU performance as the CPU deals with the</span>
    <span class="pl-c"># cropping operation.</span>
    <span class="pl-v">batch_iterator_train</span> <span class="pl-k">=</span> CropBatchIterator(<span class="pl-v">batch_size</span><span class="pl-k">=</span><span class="pl-c1">200</span>),
    <span class="pl-v">batch_iterator_test</span> <span class="pl-k">=</span> CropBatchIterator(<span class="pl-v">batch_size</span><span class="pl-k">=</span><span class="pl-c1">200</span>),

    <span class="pl-v">regression</span> <span class="pl-k">=</span> <span class="pl-c1">False</span>,
    <span class="pl-v">max_epochs</span> <span class="pl-k">=</span> <span class="pl-c1">500</span>,

    <span class="pl-c"># Deeper layer information (learning capacity, coverage...)</span>
    <span class="pl-v">verbose</span> <span class="pl-k">=</span> <span class="pl-c1">2</span>, 
)</pre></div>

<p><img src="https://cloud.githubusercontent.com/assets/19994887/16303398/bb9328a8-3950-11e6-8185-547eb1e7cd0c.png" alt="net1net2"></p>

<p>We also manage to obtain better results with nearly 99% on average, however the network still tends to be overfitting a little (the reason is probably that MNIST is too simple).</p>

<div class="highlight highlight-source-shell"><pre> epoch    train loss    valid loss    train/val    valid acc  dur
-------  ------------  ------------  -----------  -----------  -----
      1       1.18662       0.40577      2.92434      0.87733  8.72s
     ..       .......       .......      .......      .......  .....
     50       0.01686       0.04535      0.37183      0.98744  8.79s
     ..       .......       .......      .......      .......  .....
    100       0.00561       0.05057      0.11096      0.98733  8.82s
     ..       .......       .......      .......      .......  .....
    200       0.00095       0.06931      0.01376      0.98721  8.81s
     ..       .......       .......      .......      .......  .....
    300       0.00007       0.06970      0.00101      0.98930  8.76s
     ..       .......       .......      .......      .......  .....
    400       0.00004       0.07738      0.00045      0.99000  8.70s
     ..       .......       .......      .......      .......  .....
    450       0.00003       0.06610      0.00039      0.99000  8.83s
     ..       .......       .......      .......      .......  .....
    500       0.00002       0.07326      0.00030      0.98884  8.71s
</pre></div>

<h2>
<a id="further-improvements" class="anchor" href="#further-improvements" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Further improvements</h2>

<p>We can still scratch a little more performance while reducing validation loss with simple changes. First we will need to add another type of layers called <code>Dropout</code>.</p>

<blockquote>
<p>Dropout is a technique that (...) prevents overfitting and
provides a way of approximately combining exponentially many different neural network
architectures efficiently. The term “dropout” refers to dropping out units (hidden and
visible) in a neural network. By dropping a unit out, we mean temporarily removing it from
the network, along with all its incoming and outgoing connections, as shown in Figure (a).
The choice of which units to drop is random. In the simplest case, each unit is retained with
a fixed probability p independent of other units, where p can be chosen using a validation
set or can simply be set at 0.5, which seems to be close to optimal for a wide range of
networks and tasks (...).
<em>See</em> <a href="https://www.cs.toronto.edu/%7Ehinton/absps/JMLRdropout.pdf"><em>(Dropout: A Simple Way to Prevent Neural Networks from Overfitting)</em></a></p>
</blockquote>

<p><img src="https://cloud.githubusercontent.com/assets/19994887/16375020/a186beaa-3c59-11e6-892e-bf59d565257e.png" alt="dropoutlayer"></p>

<div class="highlight highlight-source-python"><pre>net3 <span class="pl-k">=</span> NeuralNet(
    <span class="pl-v">layers</span> <span class="pl-k">=</span> [(<span class="pl-s"><span class="pl-pds">'</span>input<span class="pl-pds">'</span></span>, layers.InputLayer),
              <span class="pl-c">#(...),</span>
              (<span class="pl-s"><span class="pl-pds">'</span>dropout<span class="pl-pds">'</span></span>, layers.DropoutLayer),
              <span class="pl-c">#(...)</span>
              ],
    <span class="pl-v">dropout_p</span> <span class="pl-k">=</span> <span class="pl-c1">0.3</span>,</pre></div>

<p>This is not the only change we will do to <code>net2</code>, remember why we decided to pick <code>nesterov momemtum</code> as learning method ? Optimizations that is ! What's good about the method is that it needs to have a fixed learning rate and momentum. What's even better is that <code>nolearn</code> allows us to dynamically change these values as the training occurs. We will create a custom class charged to update the value:</p>

<div class="highlight highlight-source-python"><pre><span class="pl-c"># Converts numbers into 32b floats best used w/ GPUs.</span>
<span class="pl-k">def</span> <span class="pl-en">float32</span>(<span class="pl-smi">k</span>):
    <span class="pl-k">return</span> np.cast[<span class="pl-s"><span class="pl-pds">'</span>float32<span class="pl-pds">'</span></span>](k)

<span class="pl-c"># Allows fine tuning of hyper-parameters during the learning process</span>
<span class="pl-c"># Credits to (@Karpathy)</span>
<span class="pl-k">class</span> <span class="pl-en">AdjustVariable</span>(<span class="pl-c1">object</span>):
    <span class="pl-k">def</span> <span class="pl-c1">__init__</span>(<span class="pl-smi"><span class="pl-smi">self</span></span>, <span class="pl-smi">name</span>, <span class="pl-smi">start</span><span class="pl-k">=</span><span class="pl-c1">0.03</span>, <span class="pl-smi">stop</span><span class="pl-k">=</span><span class="pl-c1">0.001</span>):
        <span class="pl-v">self</span>.name <span class="pl-k">=</span> name
        <span class="pl-v">self</span>.start <span class="pl-k">=</span> start
        <span class="pl-v">self</span>.stop <span class="pl-k">=</span> stop
        <span class="pl-v">self</span>.ls <span class="pl-k">=</span> <span class="pl-c1">None</span>

    <span class="pl-k">def</span> <span class="pl-c1">__call__</span>(<span class="pl-smi"><span class="pl-smi">self</span></span>, <span class="pl-smi">nn</span>, <span class="pl-smi">train_history</span>):
        <span class="pl-k">if</span> <span class="pl-v">self</span>.ls <span class="pl-k">is</span> <span class="pl-c1">None</span>:
            <span class="pl-v">self</span>.ls <span class="pl-k">=</span> np.linspace(<span class="pl-v">self</span>.start, <span class="pl-v">self</span>.stop, nn.max_epochs)

        epoch <span class="pl-k">=</span> train_history[<span class="pl-k">-</span><span class="pl-c1">1</span>][<span class="pl-s"><span class="pl-pds">'</span>epoch<span class="pl-pds">'</span></span>]
        new_value <span class="pl-k">=</span> float32(<span class="pl-v">self</span>.ls[epoch <span class="pl-k">-</span> <span class="pl-c1">1</span>])
        <span class="pl-c1">getattr</span>(nn, <span class="pl-v">self</span>.name).set_value(new_value)</pre></div>

<p>When called, <code>AdjustVariable</code> updates the parsed variable with its new value. But how does it work exactly ?<br>
  <code>np.linspace</code> is a numpy function used to create a 1D array ranging from [start, stop] of length max_epochs so that the new values are evenly distributed no matter the duration. <code>nolearn</code> allows us to search values in the history of the training with <code>train_history</code>. We save the latest <code>epoch</code> value and set the new values correspondingly using the Python built-in function <code>getattr</code>. Note that we need to convert the value to a GPU oriented format <code>np.float32</code>.</p>

<p>Now that we're done with the class we have to inform <code>net3</code> that it needs to use our brand new class, with <code>nolearn</code> we can do it pretty easily:</p>

<div class="highlight highlight-source-python"><pre>    on_epoch_finished<span class="pl-k">=</span>[
        AdjustVariable(<span class="pl-s"><span class="pl-pds">'</span>update_learning_rate<span class="pl-pds">'</span></span>, <span class="pl-v">start</span><span class="pl-k">=</span><span class="pl-c1">0.03</span>, <span class="pl-v">stop</span><span class="pl-k">=</span><span class="pl-c1">0.0001</span>),
        AdjustVariable(<span class="pl-s"><span class="pl-pds">'</span>update_momentum<span class="pl-pds">'</span></span>, <span class="pl-v">start</span><span class="pl-k">=</span><span class="pl-c1">0.9</span>, <span class="pl-v">stop</span><span class="pl-k">=</span><span class="pl-c1">0.999</span>),
        ],</pre></div>

<p>There is one last change to make before fitting our net. In order to dynamically change <code>update_learning_rate</code> and <code>update_momentum</code> we have to change the variable type to a Theano-type named <code>shared variable</code>. We never spoke of Theano as it is not the purpose of this write-up however I will briefly explain what it is:</p>

<blockquote>
<p>Theano is a Python library that lets you to define, optimize, and evaluate mathematical expressions, especially ones with multi-dimensional arrays (numpy.ndarray). Using Theano it is possible to attain speeds rivaling hand-crafted C implementations for problems involving large amounts of data.</p>
</blockquote>

<p>We saw that Nolearn is built on top of Lasagne right ? Well, Lasagne is to Theano as Nolearn is to Lasagne ! Nolearn's goal is to abstract as much as possible every concept in order to keep things simple and clear. Theano however, only wanted to leave most of the tedious mathematical part hidden. While Nolearn might be simpler to understand for beginners, Theano allows much more customization (such as what we're trying to achieve). Thankfully since Nolearn is a wrapper built around Theano, we can use both in the same program.  </p>

<p>A <code>shared variable</code> is a « Variable with Storage that is shared between functions that it appears in », Theano uses a lot of symbolic expressions (see: <a href="https://en.wikipedia.org/wiki/S-expression">S-expression</a>) as it helps generating C  code.</p>

<div class="highlight highlight-source-python"><pre><span class="pl-k">import</span> theano
<span class="pl-c"># (...)</span>
update_learning_rate <span class="pl-k">=</span> theano.shared(float32(<span class="pl-c1">0.03</span>)),
update_momentum <span class="pl-k">=</span> theano.shared(float32(<span class="pl-c1">0.9</span>)), </pre></div>

<p>Finally ! We have everything ready for a last run. This is what <code>net3</code> had to offer after 1000 epochs of training:</p>

<h3>
<a id="credits" class="anchor" href="#credits" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Credits</h3>

<p>Daniel Nouri (<a href="https://github.com/dnouri" class="user-mention">@dnouri</a>) author of nolearn and Andrej Karpathy (<a href="https://github.com/karpathy" class="user-mention">@karpathy</a>) for his ML courses.</p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/jcouvy/convnet-nolearn">Experimenting convolutional networks with nolearn</a> is maintained by <a href="https://github.com/jcouvy">jcouvy</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
